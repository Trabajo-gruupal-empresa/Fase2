{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "rcParams[\"font.weight\"] = \"bold\"\n",
    "rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "rcParams[\"font.size\"] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_placas = pd.read_csv('placas.csv')\n",
    "\n",
    "df_placas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_placas.isna().sum() # Verificando los valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_placas.info() # Verificando los tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_placas[\"MODULE_TEMPERATURE\"].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_placas[\"MODULE_TEMPERATURE\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_placas[\"MODULE_TEMPERATURE\"][df_placas[\"MODULE_TEMPERATURE\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_placas[20:330][[\"MODULE_TEMPERATURE\", \"AMBIENT_TEMPERATURE\", \"IRRADIATION\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_placas.drop(df_placas.dropna().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No hay nada que limpiar\n",
    "\n",
    "df_placas.shape[0] - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_filt = df_placas.dropna().reset_index(drop=True)\n",
    "df_solar_filt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis exploratorio, tratamiento y limpieza de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_filt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consultar el tipo de datos\n",
    "df_solar_filt.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_filt.dtypes[df_solar_filt.dtypes == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_solar_filt['DATE_TIME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnas a eliminar por ser informativas\n",
    "columnas_drop = [\"DATE_TIME\", \"SOURCE_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_filt2 = df_solar_filt.drop(columns = columnas_drop)\n",
    "print(\"Tamaño del tablón filtrado: \", df_solar_filt.shape)\n",
    "print(\"Tamaño del tablón nuevo: \", df_solar_filt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_filt2.dtypes.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducción de variables\n",
    "Importancia de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar la lista de features y la variable target\n",
    "target = 'MODULE_TEMPERATURE'\n",
    "features = [x for x in df_solar_filt2.columns if x != target]\n",
    "\n",
    "print(target)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_filt2[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el algoritmo de árboles de decisión\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Asignar el algortimo e indicar la profundidad máxima del árbol (con un número rotandamente grande para sobreajustar)\n",
    "arbol_importancia = DecisionTreeRegressor(max_depth=len(features)+10, random_state=42)\n",
    "\n",
    "# Entrenar un árbol con todo el conjunto de datos\n",
    "arbol_importancia.fit(X=df_solar_filt2[features], y=df_solar_filt2[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que se obtiene un R^2 muy alto. Lo desesable es que sea 1.\n",
    "y_pred_arbol = arbol_importancia.predict(X=df_solar_filt2[features])\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Métricas para evaluar la calidad del modelo\n",
    "print('Mean Absolute Error:', mean_absolute_error(df_solar_filt2[target], y_pred_arbol))\n",
    "print('Mean Absolute Percentage Error:', mean_absolute_percentage_error(df_solar_filt2[target], y_pred_arbol)*100)\n",
    "print('Mean Squared Error:', mean_squared_error(df_solar_filt2[target], y_pred_arbol))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(df_solar_filt2[target], y_pred_arbol)))\n",
    "print('R^2 coefficient of determination:', r2_score(df_solar_filt2[target], y_pred_arbol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de cada variable en el árbol ajustado\n",
    "arbol_importancia.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataframe con los datos de importancia\n",
    "importancia = pd.DataFrame(arbol_importancia.feature_importances_, index=features, columns=[\"Importancia\"])\n",
    "\n",
    "# Ordenamos los datos\n",
    "importancia.sort_values(by=importancia.columns[0], ascending=False, inplace=True)\n",
    "importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia[\"imp_acum\"] = importancia[\"Importancia\"].cumsum()\n",
    "importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de variables más importantes\n",
    "importancia.loc[importancia['imp_acum']<=0.90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = importancia.loc[importancia['imp_acum']>0.90].index.to_list()\n",
    "print(variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las variables tienen importancia, no eliminamos ninguna."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planteamiento del ejercicio de clasificación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacemos una copia del tablón filtrado para no trabajar sobre original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una copia del tablón filtrado para no trabajar sobre original\n",
    "df_solpl = df_solar_filt2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crearemos ahora una nueva columna llamada escenario\n",
    "df_solpl[\"escenario\"] = np.where(df_solpl[\"MODULE_TEMPERATURE\"]<df_solpl[\"MODULE_TEMPERATURE\"].mean(),\"frio\",\"calor\")\n",
    "df_solpl.drop([\"MODULE_TEMPERATURE\"],axis=1,inplace=True)\n",
    "df_solpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solpl.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficar primer escenario\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.violinplot(data=df_solpl, orient=\"h\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Paso 1.**  Obtención y preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparar los datos del modelo\n",
    "# Variables independientes\n",
    "X = df_solpl.drop([\"escenario\"],axis= 'columns')\n",
    "# Variable dependiente\n",
    "y = df_solpl[\"escenario\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos libreria sklear\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# tipo de escalamiento y su ajuste\n",
    "escalado = StandardScaler().fit(X)\n",
    "dataset_normal = escalado.transform(X)\n",
    "dataset_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo convertimos en un DataFrame, añadiendole sus etiquetas\n",
    "X_normal = pd.DataFrame(dataset_normal, columns=X.columns)\n",
    "print(type(X_normal))\n",
    "X_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal.describe().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la distribución de los valores estandarizados\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.violinplot(data=X_normal, orient=\"h\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Paso 2.**  Dividir el dataset en Training y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar los conjuntos de datos de entrenamiento (Training) y de prueba (Test) para las variables de entrada y salida\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normal, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"test_size\" representa la proporción del conjunto de datos a incluir en la división de Test\n",
    "print(X_train.shape[0])\n",
    "print(X_test.shape[0])\n",
    "X_train.shape[0] + X_test.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Paso 3.** Cargar y elegir el modelo de regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el módulo que corresponde al algoritmo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Asignar el algoritmo que vamos a aplicar \n",
    "log_r = LogisticRegression(max_iter= 1000, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Paso 4.** Entrenar el modelo de regresión logística con los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "log_r.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Paso 5.** Obtener las predicciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las predicciones con el conjunto de prueba\n",
    "y_pred = log_r.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir la salida del modelo (los niveles de calidad del aire)\n",
    "print(y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Paso 6.** Evaluación del modelo a través de sus métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificacion report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred),\n",
    "                               display_labels=log_r.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo del area bajo la curva ROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_pred)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
